# Stream_Vits_Zh

Stream_Vits_Zh æ˜¯ä¸€ä¸ªåŸºäº **VITS** çš„æµå¼ TTS æ–¹æ¡ˆï¼Œé€‚ç”¨äºéœ€è¦**ä½å»¶è¿Ÿ**çš„è¯­éŸ³åˆæˆåº”ç”¨ã€‚

æœ¬é¡¹ç›®åŸºäº [vits_chinese](https://github.com/PlayVoice/vits_chinese)ï¼Œæä¾›äº†ä¸€ä¸ªæ”¯æŒ**æµå¼è¾“å‡º**çš„ä¸­æ–‡ VITS æ¨¡å‹æ¥å£ï¼Œä¸“ä¸º **ä¸­æ–‡ TTS** ä»»åŠ¡ä¼˜åŒ–ã€‚

## **âœ¨ ç‰¹æ€§**

âœ… **åŸºäº VITS_chinese**ï¼šä¸“ä¸ºä¸­æ–‡è¯­éŸ³åˆæˆä¼˜åŒ–ï¼Œæä¾›é«˜è´¨é‡çš„ TTS è¾“å‡ºã€‚

âœ… **æ”¯æŒæµå¼è¾“å‡º**ï¼šä½å»¶è¿Ÿã€é€æ­¥ç”ŸæˆéŸ³é¢‘ï¼Œæé«˜å®æ—¶æ€§ã€‚

âœ… **å…¼å®¹ Coqui-TTS**ï¼šå¯ä½œä¸º **Coqui-TTS** çš„ä¸­æ–‡æµå¼æ¨¡å‹è¡¥å……ï¼Œæä¾›æ›´å¥½çš„æµå¼ TTS æ€§èƒ½ã€‚

âœ… **æ˜“äºéƒ¨ç½²**ï¼šç®€æ´çš„ API è®¾è®¡ï¼Œæ–¹ä¾¿é›†æˆï¼Œé€‚ç”¨äºå„ç§åº”ç”¨åœºæ™¯ã€‚

---

## **ğŸš€ åœ¨çº¿ Demo**

https://github.com/user-attachments/assets/788da5c5-ff62-4e09-bdfd-e33c240e1cda

---

## **ğŸ“¦ å®‰è£…ä¾èµ–**

### **1ï¸âƒ£ å…‹éš†é¡¹ç›®**
```bash
git clone https://github.com/zzl410/stream_vits_zh.git
cd stream_vits_zh
```

### **2ï¸âƒ£ å®‰è£…ä¾èµ–**
```bash
pip install -r requirements.txt
```

âš ï¸ **æ¨è Python 3.8+ ç‰ˆæœ¬**

### **3ï¸âƒ£ å®‰è£… `monotonic_align` ä¾èµ–**
```bash
cd monotonic_align
python setup.py build_ext --inplace
cd ..
```

---

## **ğŸ“¥ ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¨ç†**

### **1ï¸âƒ£ ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹**

ğŸ”— [vits_chinese/releases](https://github.com/zzl410/stream_vits_zh/releases/tag/v1.0)

å°† **`prosody_model.pt`** æ”¾å…¥ `./bert/prosody_model.pt`

å°† **`vits_bert_model.pth`** æ”¾å…¥ `./vits_bert_model.pth`

### **2ï¸âƒ£ è¿è¡Œæ¨ç†**
```bash
python stream_example.py
```

ç”Ÿæˆçš„éŸ³é¢‘å—å°†**é€æ­¥è¾“å‡º**ï¼Œæ”¯æŒå®æ—¶æ’­æ”¾ã€‚

---

## **ğŸ“Œ è´¡çŒ®ï¼šæä¾›æµå¼ VITS ä¸­æ–‡ TTS æ¥å£**

æœ¬é¡¹ç›®æä¾›äº†ä¸€ä¸ªèƒ½ **æµå¼è¾“å‡ºä¸­æ–‡** çš„ VITS æ¨¡å‹æ¥å£ï¼Œé€‚ç”¨äº**ä½å»¶è¿Ÿ TTS** åº”ç”¨ï¼Œå¹¶å¯ä½œä¸º **Coqui-TTS** çš„è¡¥å……ã€‚

### **ğŸ”§ æ ¸å¿ƒæ¥å£ï¼š`stream_vits_zh.py`**

```python
def inference_stream(config: str, model: str, txt: str):
    """
    è¿›è¡Œ VITS æ¨ç†ï¼Œæµå¼è¿”å›éŸ³é¢‘å—ã€‚
    
    Args:
        config (str): é…ç½®æ–‡ä»¶è·¯å¾„ã€‚
        model (str): è®­ç»ƒæ¨¡å‹è·¯å¾„ã€‚
        txt (str): è¾“å…¥æ–‡æœ¬ã€‚
    
    Yields:
        np.ndarray: å•ä¸ªæµå¼éŸ³é¢‘å—ã€‚
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    bert_path = os.path.join(os.path.dirname(__file__), 'bert')
    tts_front = VITS_PinYin(bert_path, device)
    hps = utils.get_hparams_from_file(config)
    
    net_g = utils.load_class(hps.train.eval_class)(
        len(symbols),
        hps.data.filter_length // 2 + 1,
        hps.train.segment_size // hps.data.hop_length,
        **hps.model)
    utils.load_model(model, net_g)
    net_g.eval()
    net_g.to(device)
    
    phonemes, char_embeds = tts_front.chinese_to_phonemes(txt)
    input_ids = cleaned_text_to_sequence(phonemes)
    buffer_queue = queue.Queue(maxsize=5)
    stop_event = threading.Event()
    
    def producer():
        with torch.no_grad():
            x_tst = torch.LongTensor(input_ids).unsqueeze(0).to(device)
            x_tst_lengths = torch.LongTensor([len(input_ids)]).to(device)
            x_tst_prosody = torch.FloatTensor(char_embeds).unsqueeze(0).to(device)
            
            for chunk in net_g.inference_stream(x_tst, x_tst_lengths, x_tst_prosody, noise_scale=0.5, length_scale=1):
                buffer_queue.put(chunk)
        stop_event.set()
    
    producer_thread = threading.Thread(target=producer)
    producer_thread.start()
    
    while not (stop_event.is_set() and buffer_queue.empty()):
        chunk = buffer_queue.get()
        yield chunk
```

---

## **ğŸŒŸ æ¬¢è¿ Star & è´¡çŒ®**

ğŸ’– å¦‚æœä½ è§‰å¾—è¿™ä¸ªé¡¹ç›®æœ‰ç”¨ï¼Œè¯·ç»™ä¸ª â­ **Star** æ”¯æŒï¼

ğŸ“¢ æœŸå¾…ä½ çš„ PR å’Œ Issue åé¦ˆï¼Œå…±åŒä¼˜åŒ– Stream_Vits_Zh ğŸš€

ğŸ“¬ **è”ç³»ä½œè€…ï¼š** [GitHub Issues](https://github.com/zzl410/stream_vits_zh/issues)

---


